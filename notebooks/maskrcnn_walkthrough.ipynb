{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN End-to-End Walkthrough\n",
    "\n",
    "This notebook shows how to train, evaluate, and run inference with the lightweight Mask R-CNN setup in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if running in a fresh environment)\n",
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"..\");\n",
    "\n",
    "from config import Config\n",
    "from dataset import InstanceSegmentationDataset\n",
    "from transforms import build_transforms\n",
    "from model import load_for_inference\n",
    "\n",
    "cfg = Config()\n",
    "cfg.train_data_dir = Path(\"../data/train\")\n",
    "cfg.val_data_dir = Path(\"../data/val\")\n",
    "cfg.output_dir = Path(\"../outputs\")\n",
    "cfg.classes = [\"__background__\", \"object\"]  # edit to your classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "Each split lives under `data/<split>/images` and `data/<split>/annotations`. Every image has a matching JSON named after the stem. Example annotation:\n",
    "```json\n",
    "{\n",
    "  \"boxes\": [[x1, y1, x2, y2]],\n",
    "  \"labels\": [\"object\"],\n",
    "  \"polygons\": [\n",
    "    [[x, y], [x, y], [x, y]]\n",
    "  ],\n",
    "  \"iscrowd\": [0]\n",
    "}\n",
    "```\n",
    "Polygons are rasterized into binary masks; provide multiple polygons per instance if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: create a tiny synthetic dataset for a smoke test\n",
    "import json\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def make_synthetic_split(split: str, count: int = 4):\n",
    "    root = Path(f\"../data/{split}\")\n",
    "    (root / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (root / \"annotations\").mkdir(parents=True, exist_ok=True)\n",
    "    for i in range(count):\n",
    "        img = Image.new(\"RGB\", (256, 256), color=\"white\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        x1, y1 = random.randint(20, 80), random.randint(20, 80)\n",
    "        x2, y2 = x1 + random.randint(60, 120), y1 + random.randint(60, 120)\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3, fill=\"pink\")\n",
    "        img_path = root / \"images\" / f\"img_{i:03d}.png\"\n",
    "        img.save(img_path)\n",
    "\n",
    "        ann = {\n",
    "            \"boxes\": [[x1, y1, x2, y2]],\n",
    "            \"labels\": [\"object\"],\n",
    "            \"polygons\": [[[x1, y1], [x2, y1], [x2, y2], [x1, y2]]],\n",
    "            \"iscrowd\": [0],\n",
    "        }\n",
    "        with open(root / \"annotations\" / f\"img_{i:03d}.json\", \"w\") as f:\n",
    "            json.dump(ann, f, indent=2)\n",
    "\n",
    "make_synthetic_split(\"train\", 12)\n",
    "make_synthetic_split(\"val\", 4)\n",
    "print(\"Synthetic data ready under ../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (adjust flags as needed)\n",
    "!python ../train.py --train-data ../data/train --val-data ../data/val --output-dir ../outputs --epochs 2 --batch-size 2 --device cpu --no-amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on validation images\n",
    "!python ../infer.py --images ../data/val/images --checkpoint ../outputs/model_epoch_2.pth --output-dir ../predictions --device cpu --score-threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate IoU@0.5 precision/recall\n",
    "!python ../eval.py --data ../data/val --checkpoint ../outputs/model_epoch_2.pth --device cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
