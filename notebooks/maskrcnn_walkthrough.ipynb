{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN End-to-End (no shell calls)\n",
    "Train, infer, and evaluate directly from Python so you can see what runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n", 
    "sys.path.append(\"..\");\n",
    "\n",
    "from config import Config\n",
    "from dataset import InstanceSegmentationDataset\n",
    "from transforms import build_transforms\n",
    "from model import build_model, load_for_inference\n",
    "from engine import train_one_epoch, evaluate\n",
    "from utils import collate_fn, save_checkpoint, set_seed\n",
    "from infer import run_inference\n",
    "from eval import run_eval\n",
    "\n",
    "cfg = Config()\n",
    "cfg.train_data_dir = Path(\"../data/train\")\n",
    "cfg.val_data_dir = Path(\"../data/val\")\n",
    "cfg.output_dir = Path(\"../outputs\")\n",
    "cfg.classes = [\"__background__\", \"object\"]  # edit for your data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format reminder\n",
    "- Images: `data/<split>/images/*.jpg|png`\n",
    "- Annotations: `data/<split>/annotations/<image_stem>.json`\n",
    "- JSON keys: `boxes`, `labels`, `polygons` (list of point lists), optional `iscrowd`.\n",
    "\n",
    "Below we create a tiny synthetic dataset you can skip if you already have data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def make_synthetic_split(split: str, count: int = 6):\n",
    "    root = Path(f\"../data/{split}\")\n",
    "    (root / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (root / \"annotations\").mkdir(parents=True, exist_ok=True)\n",
    "    for i in range(count):\n",
    "        img = Image.new(\"RGB\", (256, 256), color=\"white\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        x1, y1 = random.randint(20, 80), random.randint(20, 80)\n",
    "        x2, y2 = x1 + random.randint(60, 120), y1 + random.randint(60, 120)\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3, fill=\"pink\")\n",
    "        img_path = root / \"images\" / f\"img_{i:03d}.png\"\n",
    "        img.save(img_path)\n",
    "\n",
    "        ann = {\n",
    "            \"boxes\": [[x1, y1, x2, y2]],\n",
    "            \"labels\": [\"object\"],\n",
    "            \"polygons\": [[[x1, y1], [x2, y1], [x2, y2], [x1, y2]]],\n",
    "            \"iscrowd\": [0],\n",
    "        }\n",
    "        with open(root / \"annotations\" / f\"img_{i:03d}.json\", \"w\") as f:\n",
    "            json.dump(ann, f, indent=2)\n",
    "    print(f\"Synthetic {split} set written to {root}\")\n",
    "\n",
    "# comment out if you already have data\n",
    "make_synthetic_split(\"train\", 12)\n",
    "make_synthetic_split(\"val\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datasets/dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = InstanceSegmentationDataset(cfg.train_data_dir, transforms=build_transforms(True, cfg.image_size), classes=cfg.classes)\n",
    "val_ds = InstanceSegmentationDataset(cfg.val_data_dir, transforms=build_transforms(False, cfg.image_size, with_augs=False), classes=cfg.classes)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers, collate_fn=collate_fn)\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (explicit loop)\n",
    "Runs a small number of epochs, logs losses, and saves a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "model = build_model(cfg).to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=cfg.learning_rate, momentum=cfg.momentum, weight_decay=cfg.weight_decay)\n",
    "scheduler = MultiStepLR(optimizer, milestones=list(cfg.lr_steps), gamma=cfg.lr_gamma)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp)\n",
    "\n",
    "num_epochs = 2  # bump as needed\n",
    "ckpt_path = cfg.output_dir / \"model_notebook.pth\"\n",
    "cfg.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch, cfg, scaler)\n",
    "    val_loss = evaluate(model, val_loader, device, cfg)\n",
    "    scheduler.step()\n",
    "    save_checkpoint({\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict(), \"epoch\": epoch + 1, \"config\": cfg}, ckpt_path)\n",
    "    print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} saved={ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference (Python call)\n",
    "Loads the saved checkpoint and writes overlays/JSON to `../predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = Path(\"../predictions\")\n",
    "model_infer = load_for_inference(cfg, checkpoint_path=str(ckpt_path), device=device)\n",
    "images = list((cfg.val_data_dir / \"images\").glob(\"*.png\")) or list((cfg.val_data_dir / \"images\").glob(\"*.jpg\"))\n",
    "results = run_inference(model_infer, images, pred_dir, device, cfg)\n",
    "results[:1]  # show first prediction dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (Python call)\n",
    "Computes precision/recall/F1 at IoU=0.5 using `eval.run_eval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(cfg, ckpt_path, cfg.val_data_dir, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
